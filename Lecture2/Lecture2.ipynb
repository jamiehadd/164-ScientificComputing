{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fff933b-143a-4ec1-97a0-d7002d4088cb",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Lecture 2: Algorithms, Stability, Linear algebra review\"\n",
    "author: \"Jamie Haddock\"\n",
    "format: \n",
    "    revealjs:\n",
    "        output-file: Lecture2_slides\n",
    "        slide-number: true\n",
    "        chalkboard: \n",
    "            buttons: false\n",
    "        preview-links: auto\n",
    "        logo: figs/hmc.png\n",
    "        css: input/slides.css\n",
    "        incremental: true\n",
    "        smaller: true\n",
    "        code-fold: true\n",
    "    html: \n",
    "        code-fold: true\n",
    "    pdf:\n",
    "        documentclass: article\n",
    "        toc: true\n",
    "        number-sections: true\n",
    "        geometry:\n",
    "          - top=1in\n",
    "          - left=1in\n",
    "          - bottom=1in\n",
    "          - right=1in\n",
    "format-links: false\n",
    "jupyter: julia-1.9\n",
    "filters: \n",
    "  - input/remove-pause.lua\n",
    "execute:\n",
    "  echo: true\n",
    "  eval: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55709479",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "A problem $f(x)$ can typically only be approximated in finite precision (e.g., floating-point representation).  A complete set of instructions for transforming data into a result is called an **algorithm**.  In most cases, we can represent the output from the algorithm by another function $\\tilde{f}(x)$, and for the next few lectures, we will consider the algorithm to be executed in finite precision.\n",
    "\n",
    "## Example\n",
    "\n",
    "Suppose our problem is to evaluate the value of a polynomial given a real input $x$, $$f(x) = 5x^3 + 4x^2 + 3x + 2.$$  \n",
    "\n",
    "Here are two possible algorithms for evaluating this polynomial:\n",
    "\n",
    "* Evalate $x^2 = x\\times x$ and $x^3 = x \\times x^3$ with two multiplications, then calculate $5x^3, 4x^2,$ and $3x$ with three additional multiplications, and finally evaluate $5x^3 + 4x^2 + 3x + 2$ with three additions, for a total of eight arithmetic operations.\n",
    "* Organize the polynomial as $2 + x(3 + x(4 + 5x))$ which requires three multiplications and three additions, for a total of six arithmetic operations.\n",
    "\n",
    ". . . \n",
    "\n",
    "This savings may seem small, but saving 25\\% of the total operations can be *huge* when the numbe of operations is in the millions or billions!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b98e1",
   "metadata": {},
   "source": [
    "## Algorithms as Code\n",
    "\n",
    "The technique we just saw in the previous example is known as Horner's rule or algorithm  We have that $p(x) = c_1 + c_2x + c_3x^2 + \\cdots + c_nx^{n-1} = c_1 + x(c_2 + \\cdots + x(c_{n-2} + x(c_{n-1} + c_nx))).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c12669-a869-46d9-aa62-bbb2a02b1783",
   "metadata": {},
   "source": [
    "<!--\n",
    "[verbose test]{.content-hidden when-format=\"revealjs\" when-format=\"pptx\"}\n",
    "\n",
    "::: {.callout-caution icon=false}\n",
    "## Exercise: \n",
    "\n",
    ":::\n",
    "\n",
    "<details><summary>Answer:</summary> </details>\n",
    "\n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "## Definition: \n",
    " \n",
    ":::\n",
    "\n",
    "\n",
    "::: {.callout-tip icon=false}\n",
    "## Note: \n",
    " \n",
    ":::\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec0cbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "horner (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    horner(c,x)\n",
    "\n",
    "Evaluate a polynomial whose coefficients are given in ascending (according to\n",
    "associated monomial degree) order in 'c', at the point 'x' using Horner's\n",
    "algorithm.\n",
    "\"\"\"\n",
    "\n",
    "function horner(c,x)\n",
    "    n = length(c)\n",
    "    y = c[n]\n",
    "    for k in n-1:-1:1\n",
    "        y = x*y + c[k]\n",
    "    end\n",
    "    return y\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a82c800",
   "metadata": {},
   "source": [
    "[In the code above, the `length` function returns the number of elements in vector `c`.  We use `c[n]` to access the $n$th element of vector `c`.  The polynomial value is evaluated recursively in the for loop.  Note the format for the range for `k` -- it ranges from $n-1$ to 1 with steps of size $-1$.]{.content-hidden when-format='revealjs' when-format='pptx'} \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b7d18",
   "metadata": {},
   "source": [
    "Let's use this function to evaluate the value a given polynomial! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0abf81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21600000000000041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = [-1,3,-3,1]\n",
    "\n",
    "horner(c,1.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7377ba39",
   "metadata": {},
   "source": [
    "# Stability\n",
    "\n",
    "If we solve a problem $f$ using a computer algorithm and we see a large error in the result, we might suspect that the problem has poor conditioning.  However, it could also be that the *algorithm* introduced additional error.  When error in the output of an algorithm exceeds what the problem conditioning explains, we say that the algorithm is **unstable**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cefd5b0",
   "metadata": {},
   "source": [
    "## Case Study: Stability\n",
    "\n",
    "We're returning to the problem of calculating roots of a quadratic polynomial; that is finding values $t$ such that $at^2 + bt + c = 0$.  In Lecture 1, we showed that this problem is ill-conditioned if and only if the roots are close together relative to their size.\n",
    "\n",
    ". . .\n",
    "\n",
    "Thus, find the roots of the polynomial $p(x) = (x- 10^6)(x - 10^{-6}) = x^2 - (10^6 + 10^{-6})x + 1$ is a well-conditioned problem.  As we saw previously, the quadratic formula is an algorithm for this problem.\n",
    "\n",
    ". . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd123ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x₁ = (-b + sqrt(b ^ 2 - (4a) * c)) / (2a) = 1.0e6\n",
      "x₂ = (-b - sqrt(b ^ 2 - (4a) * c)) / (2a) = 1.00000761449337e-6\n"
     ]
    }
   ],
   "source": [
    "a = 1; b = -(1e6+1e-6); c = 1;\n",
    "@show x₁ = (-b + sqrt(b^2 - 4a*c)) / 2a;\n",
    "@show x₂ = (-b - sqrt(b^2 - 4a*c)) / 2a;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c4dd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The larger root has no error, but now we measure the relative error in the smaller root!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b4bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurate_digits = -(log10(error)) = 5.118358987126217\n"
     ]
    }
   ],
   "source": [
    "error = abs(1e-6 - x₂) / 1e-6\n",
    "@show accurate_digits = -log10(error);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3354746a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u₁ = b ^ 2 = 1.000000000002e12\n",
      "u₂ = u₁ - 4 = 9.99999999998e11\n",
      "u₃ = sqrt(u₂) = 999999.999999\n",
      "u₄ = -u₃ - b = 2.00001522898674e-6\n",
      "u₅ = u₄ / 2 = 1.00000761449337e-6\n"
     ]
    }
   ],
   "source": [
    "@show u₁ = b^2;\n",
    "@show u₂ = u₁ - 4;\n",
    "@show u₃ = sqrt(u₂);\n",
    "@show u₄ = -u₃ - b;\n",
    "@show u₅ = u₄/2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93cb12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Since $a = c = 1$, we'll assume these are represented exactly, and consider only the condition number with respect to $b$.  We can see where the instability in the smaller root calculation came from by considering the condition number of each of the sub-problems encountered.\n",
    "\n",
    ". . .\n",
    "\n",
    "| Problem $f$ | $\\kappa_f$ |\n",
    "|-------------|------------|\n",
    "| $u_1 = f_1(b) = b^2$ | $\\kappa_{f_1}(b) = 2$ |\n",
    "| $u_2 = f_2(u_1) = u_1 - 4$ | $\\kappa_{f_2}(u_1) \\approx 1$ |\n",
    "| $u_3 = f_3(u_2) = \\sqrt{u_2}$ | $\\kappa_{f_3}(u_2) = 1/2$ |\n",
    "| $u_4 = f_4(u_3) = -(u_3 + b)$ | $\\kappa_{f_4}(u_3) \\approx 5 \\times 10^{11}$ | \n",
    "| $u_5 = f_5(u_4) = u_4/2$ | $\\kappa_{f_5}(u_4) = 1$ |\n",
    "\n",
    ". . .\n",
    "\n",
    "We expect to lose 11 digits of accuracy in the fourth step of this algorithm.  Here the issue is the subtractive cancellation between $\\sqrt{b^2 - 4ac}$ and $b$!\n",
    "\n",
    ". . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3106ef",
   "metadata": {},
   "source": [
    "::: {.callout-tip icon=false}\n",
    "## Note: \n",
    "The quadratic formula is *unstable* for computing polynomial roots in finite precision!  The problem of calculating the roots is not unstable (as we saw previously), it is simply that the specific computational steps we took to calculate this root is unstable as a subroutine is ill-conditioned.\n",
    ":::\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523f952",
   "metadata": {},
   "source": [
    "We can compute this root with no error using a different algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf075588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x₂ = c / (a * x₁) = 1.0e-6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@show x₂ = c / (a * x₁);\n",
    "\n",
    "abs(x₂ - 1e-6) / 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c78a1",
   "metadata": {},
   "source": [
    "These two algorithms are equivalent when using real numbers and exact arithmetic, but the outputs they calculate in practice are perturbed by finite precision representation in each step and depend upon the specific order of operation.\n",
    "\n",
    ". . .\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Fact: \n",
    "The sensitivity of a problem $f(x)$ is governed only by $\\kappa_f$, but the sensitivity of an algorithm depends on the condition numbers of all its individual steps.\n",
    ":::\n",
    "\n",
    ". . .\n",
    "\n",
    "This may seem scary and complicated, but most simple operations are well-conditioned most of the time!  Exceptions are usually due to $|f(x)|$ being much smaller than $|x|$, and the most common culprit (by far!) is subtractive cancellation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57759f8f",
   "metadata": {},
   "source": [
    "## Backward error\n",
    "\n",
    "If a problem $f(x)$ has poor conditioning, event just the act of rounding the data to floating-point representation may introduce large errors in the result.  It's not reasonable to expect that algorithms $\\tilde{f}$ will have small error in the sense that $\\tilde{f}(x) \\approx f(x)$.\n",
    "\n",
    ". . .\n",
    "\n",
    "Numerical analysts instead prefer to characterize the error in a different way -- instead of asking \"Did you get nearly the right answer?\", we ask \"Did you answer nearly the right question?\"\n",
    "\n",
    ". . . \n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "## Definition: Backward error\n",
    "\n",
    "Let $\\tilde{f}$ be an algorithm for the problem $f$.  Let $y = f(x)$ be an exact result and $\\tilde{y} = \\tilde{f}(x)$ be its approximation by the algorithm.  If there is a value $\\tilde{x}$ such that $f(\\tilde{x}) = \\tilde{y}$, then the **relative backward error** in $\\tilde{y}$ is $$\\frac{|\\tilde{x} - x|}{|x|}.$$  The **absolute backward error** is $|\\tilde{x} - x|$.  \n",
    ":::\n",
    "\n",
    ". . .\n",
    "\n",
    "Backward error analysis causes us to ask \"What is the problem our algorithm actually solved?\" and to measure the distance between the ideal data and this alternative input to $f$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdc182",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "![](figs/backward_error.png){height=200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b7acef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.11/Project.toml`\n",
      "  \u001b[90m[f27b6e38] \u001b[39m\u001b[92m+ Polynomials v4.0.13\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"Polynomials\")\n",
    "using Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429ab24",
   "metadata": {},
   "source": [
    "[We need access to some code from the Julia package `Polynomials`.  We first must use the pre-installed Julia package `Pkg` which we allow by using the command `using Pkg`.  The command `Pkg.add(\"Polynomials\")` installs the package `Polynomials` for the Julia installation to access.  Note: we only have to do this once!  Then, forevermore, we can use the command `using Polynomials` to allow access to these functions.]{.content-hidden when-format='revealjs' when-format='pptx'} \n",
    "\n",
    "We can build the polynomial $p$ from its roots, $-2, -1, 1, 1, 3, 6$.  We do this so we know the exact roots of the polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1482b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "36.0 &#45; 36.0&#8729;x &#45; 43.0&#8729;x<sup>2</sup> &#43; 44.0&#8729;x<sup>3</sup> &#43; 6.0&#8729;x<sup>4</sup> &#45; 8.0&#8729;x<sup>5</sup> &#43; 1.0&#8729;x<sup>6</sup>"
      ],
      "text/latex": [
       "$36.0 - 36.0\\cdot x - 43.0\\cdot x^{2} + 44.0\\cdot x^{3} + 6.0\\cdot x^{4} - 8.0\\cdot x^{5} + 1.0\\cdot x^{6}$"
      ],
      "text/plain": [
       "Polynomial(36.0 - 36.0*x - 43.0*x^2 + 44.0*x^3 + 6.0*x^4 - 8.0*x^5 + 1.0*x^6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = [-2.0, -1, 1, 1, 3, 6]\n",
    "p = fromroots(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ef2fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49c88b9",
   "metadata": {},
   "source": [
    "Now, we compute the roots of $p$ using an algorithm and see how much error has been introduced into each root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43764acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       " -1.9999999999999993\n",
       " -1.0000000000000002\n",
       "  0.9999999876576552\n",
       "  1.0000000123423434\n",
       "  3.0000000000000036\n",
       "  5.999999999999993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r̃ = sort(roots(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8011483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root errors:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       " -3.3306690738754696e-16\n",
       " -2.220446049250313e-16\n",
       "  1.2342344812843464e-8\n",
       "  1.2342343369553532e-8\n",
       "  1.1842378929335002e-15\n",
       "  1.1842378929335002e-15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"Root errors:\")\n",
    "@. abs(r - r̃) / r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799e19c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74ff6e",
   "metadata": {},
   "source": [
    "Next, we build a polynomial $\\tilde{p}$ from these approximate roots and check how far these output coefficients have deviated from the true coefficients.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b067b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "35.999999999999936 &#45; 35.99999999999999&#8729;x &#45; 42.99999999999993&#8729;x<sup>2</sup> &#43; 43.99999999999997&#8729;x<sup>3</sup> &#43; 5.999999999999998&#8729;x<sup>4</sup> &#45; 7.999999999999996&#8729;x<sup>5</sup> &#43; 1.0&#8729;x<sup>6</sup>"
      ],
      "text/latex": [
       "$35.999999999999936 - 35.99999999999999\\cdot x - 42.99999999999993\\cdot x^{2} + 43.99999999999997\\cdot x^{3} + 5.999999999999998\\cdot x^{4} - 7.999999999999996\\cdot x^{5} + 1.0\\cdot x^{6}$"
      ],
      "text/plain": [
       "Polynomial(35.999999999999936 - 35.99999999999999*x - 42.99999999999993*x^2 + 43.99999999999997*x^3 + 5.999999999999998*x^4 - 7.999999999999996*x^5 + 1.0*x^6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p̃ = fromroots(r̃)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91538c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients errors:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7-element Vector{Float64}:\n",
       "  1.7763568394002505e-15\n",
       " -1.9737298215558337e-16\n",
       " -1.6524249668839539e-15\n",
       "  6.459479416000911e-16\n",
       "  2.9605947323337506e-16\n",
       " -5.551115123125783e-16\n",
       "  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c, c̃ = coeffs(p), coeffs(p̃)\n",
    "println(\"Coefficients errors:\")\n",
    "@. abs(c - c̃) / c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8525ed",
   "metadata": {},
   "source": [
    ". . .\n",
    "\n",
    "Even though some computed roots were relatively far from the exact values, they are roots of a polynomial that is nearby to the ideal polynomial!  In other words, we solved a problem nearby to the original problem, even if the results were quite far apart.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbc472",
   "metadata": {},
   "source": [
    "::: {.callout-warning icon=false}\n",
    "## Fact: \n",
    "\n",
    "For a poorly conditioned problem, we can really only hope for small backward error.  Informally, if an algorithm always produces small backward error then it is stable.  The converse is not ture -- some stable algorithms may produce a large backward error!\n",
    ":::\n",
    "\n",
    ". . .\n",
    "\n",
    "As an example, the algorithm $f(x) = x + 1$ is stable, but not backward stable.  If $|x| < \\epsilon_{\\text{mach}}/2,$ then the computed result is $\\tilde{f}(x) = 1$ since there are no floating points between $1$ and $1 + \\epsilon_{\\text{mach}}$.  \n",
    "\n",
    ". . .\n",
    "\n",
    "Hence, the only choice for a real $\\tilde{x}$ so that $f(\\tilde{x}) = \\tilde{f}(x) = 1$ is $\\tilde{x} = 0$.  Then $|\\tilde{x} - x|/|x| = 1$ -- 100\\% backward error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d8dd3b",
   "metadata": {},
   "source": [
    "# Linear Algebra Review\n",
    "\n",
    "## Matrix Multiplication\n",
    "\n",
    "There are two important (and equivalent) views of matrix multiplication.  Let $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}, \\mathbf{B} \\in \\mathbb{R}^{n \\times p}$ and $\\mathbf{C} = \\mathbf{A}\\mathbf{B} \\in \\mathbb{R}^{m \\times p}$.  \n",
    "\n",
    ". . .\n",
    "\n",
    "The entries of $\\mathbf{C} = \\mathbf{A}\\mathbf{B}$ may be calculated by the *inner product*, $$\\mathbf{C}_{ij} = \\sum_{k = 1}^n \\mathbf{A}_{ik}\\mathbf{B}_{kj}.$$\n",
    "\n",
    ". . .\n",
    "\n",
    "The alternative view of matrix multiplication is as a sum of rank-one matrices formed as *outer products* of corresponding columns of $\\mathbf{A}$ and rows of $\\mathbf{B}$, $$\\mathbf{C} = \\sum_{k = 1}^n \\mathbf{A}_{:k} \\mathbf{B}_{k:}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70200a5",
   "metadata": {},
   "source": [
    "## Matrix-vector multiplication\n",
    "\n",
    "Using the previous interpretations of matrix multiplications, we can better understand the special case of matrix-vector multiplication.  Consider computing $\\mathbf{A}\\mathbf{v}$ for matrix $\\mathbf{A} \\in \\mathbb{R}^{m times n}$ and vector $\\mathbf{v} \\in \\mathbb{R}^n$. \n",
    "\n",
    ". . .\n",
    "\n",
    "We have that $$\\mathbf{A}\\mathbf{v} = v_1 \\mathbf{a}_1 + \\cdots + v_n \\mathbf{a}_n$$ where $\\mathbf{a}_i$ is the $i$th columns of $\\mathbf{A}$.\n",
    "\n",
    ". . .\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Fact: \n",
    "Multiplying a matrix on the right by a column vector, $\\mathbf{A}\\mathbf{v}$, produces a linear combination of the columns of the matrix.\n",
    ":::\n",
    "\n",
    ". . .\n",
    "\n",
    "We may transpose the matrix-vector product to get:\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Fact: \n",
    "\n",
    "Multiplying a matrix on the left by a row vector produces a linear combination of the rows of the matrix.\n",
    ":::\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5d5581",
   "metadata": {},
   "source": [
    "::: {.callout-warning icon=false}\n",
    "## Fact: \n",
    "\n",
    "A matrix-matrix product is a horizontal concatenation of matrix-vector products involving the columns of the right-hand matrix.  Equivalently, a matrix-matrix product is also a vertical concatenation of vector-matrix products involving the rows of the left-hand matrix.\n",
    ":::\n",
    "\n",
    ". . .\n",
    "\n",
    "Recall the following important theorem:\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Theorem: \n",
    "The following statements are equivalent:\n",
    "1. $\\mathbf{A}$ is nonsingular\n",
    "2. $(\\mathbf{A}^{-1})^{-1} = \\mathbf{A}$\n",
    "3. $\\mathbf{A}\\mathbf{x} = \\mathbf{0}$ implies that $\\mathbf{x} = \\mathbf{0}$\n",
    "4. $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ has a unique solution, $\\mathbf{x} = \\mathbf{A}^{-1} \\mathbf{b}$, for any $n$-vector $\\mathbf{b}$\n",
    ":::\n",
    "\n",
    ". . .\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Theorem: Spectral Theorem\n",
    "\n",
    "Let $\\mathbf{A}$ be a real, $n \\times n$ matrix.  Then $\\mathbf{A}$ is symmetric if and only if $\\mathbf{A}$ is orthogonally diagonalizable.\n",
    ":::\n",
    "\n",
    "Recall that this means $\\mathbf{A} = \\mathbf{Q}^\\top \\mathbf{D} \\mathbf{Q}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f790bf16",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "![](figs/four_subspaces.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](figs/fundamental_theorem.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
