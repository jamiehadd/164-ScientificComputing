{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fff933b-143a-4ec1-97a0-d7002d4088cb",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Lecture 6: Conditioning of linear systems, Matrix structure\"\n",
    "author: \"Jamie Haddock\"\n",
    "format: \n",
    "    revealjs:\n",
    "        output-file: Lecture6_slides\n",
    "        slide-number: true\n",
    "        chalkboard: \n",
    "            buttons: false\n",
    "        preview-links: auto\n",
    "        logo: figs/hmc.png\n",
    "        css: input/slides.css\n",
    "        incremental: true\n",
    "        smaller: true\n",
    "        code-fold: true\n",
    "    html: \n",
    "        code-fold: true\n",
    "    pdf:\n",
    "        documentclass: article\n",
    "        toc: true\n",
    "        number-sections: true\n",
    "        geometry:\n",
    "          - top=1in\n",
    "          - left=1in\n",
    "          - bottom=1in\n",
    "          - right=1in\n",
    "format-links: false\n",
    "jupyter: julia-1.9\n",
    "filters: \n",
    "  - input/remove-pause.lua\n",
    "execute:\n",
    "  echo: true\n",
    "  eval: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b2e92",
   "metadata": {},
   "source": [
    "## Conditioning of Linear Systems\n",
    "\n",
    "We consider now the conditioning of solving the square linear system $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$.  Here, the data is $\\mathbf{A}$ and $\\mathbf{b}$, and the solution is $\\mathbf{x}$.\n",
    "\n",
    ". . .\n",
    "\n",
    "For simplicity, we'll imagine that there are perturbations only to $\\mathbf{b}$, while $\\mathbf{A}$ is fixed.  Suppose $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ is perturbed to $$\\mathbf{A}(\\mathbf{x} + \\mathbf{h}) = \\mathbf{b} + \\mathbf{d}.$$  \n",
    "\n",
    ". . .\n",
    "\n",
    "The condition number is the relative change in the solution divided by the relative change in the data, $$\\frac{\\frac{\\|\\mathbf{h}\\|}{\\|\\mathbf{x}\\|}}{\\frac{\\|\\mathbf{d}\\|}{\\|\\mathbf{b}\\|}} = \\frac{\\|\\mathbf{h}\\| \\|\\mathbf{b}\\|}{\\|\\mathbf{d}\\|\\|\\mathbf{x}\\|}.$$\n",
    "\n",
    "---\n",
    "\n",
    "Since $\\mathbf{h} = \\mathbf{A}^{-1}\\mathbf{d}$, we can bound $\\|\\mathbf{h}\\|$ as $$\\|\\mathbf{h}\\| \\le \\|\\mathbf{A}^{-1}\\|\\|\\mathbf{d}\\|.$$\n",
    "\n",
    ". . .\n",
    "\n",
    "Similarly, we have $\\|\\mathbf{b}\\| \\le \\|\\mathbf{A}\\| \\|\\mathbf{x}$ and so $$\\frac{\\|\\mathbf{h}\\| \\|\\mathbf{b}\\|}{\\|\\mathbf{d}\\|\\|\\mathbf{x}\\|} \\le \\frac{\\|\\mathbf{A}^{-1}\\|\\|\\mathbf{d}\\|\\|\\mathbf{A}\\|\\|\\mathbf{x}\\|}{\\|\\mathbf{d}\\|\\|\\mathbf{x}\\|} = \\|\\mathbf{A}^{-1}\\|\\|\\mathbf{A}\\|.$$\n",
    "\n",
    ". . .\n",
    "\n",
    "This bound is tight -- the inequalities are equations for some choices of $\\mathbf{b}$ and $\\mathbf{d}$.\n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "## Definition: Matrix condition number\n",
    "\n",
    "The **matrix condition number** of an invertible square matrix $\\mathbf{A}$ is $$\\kappa(\\mathbf{A}) = \\|\\mathbf{A}^{-1}\\|\\|\\mathbf{A}\\|.$$  This value depends on the choice of norm; a subscript on $\\kappa$ such as 1, 2, or $\\infty$ is used if clarification is needed.  If $\\mathbf{A}$ is singular, we define $\\kappa(\\mathbf{A}) = \\infty$.  \n",
    ":::\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569049f",
   "metadata": {},
   "source": [
    "::: {.callout-warning icon=false}\n",
    "## Theorem: Conditioning of linear systems\n",
    "If $\\mathbf{A}(\\mathbf{x} + \\triangle \\mathbf{x}) = \\mathbf{b} + \\triangle \\mathbf{b}$, then $$\\frac{\\|\\triangle \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\le \\kappa(\\mathbf{A}) \\frac{\\|\\triangle \\mathbf{b}\\|}{\\|\\mathbf{b}\\|}.$$\n",
    "\n",
    "If $(\\mathbf{A} + \\triangle \\mathbf{A})(\\mathbf{x} + \\triangle \\mathbf{x}) = \\mathbf{b}$, then $$\\frac{\\|\\triangle \\mathbf{x}\\|}{\\|\\mathbf{x}\\|} \\le \\kappa(\\mathbf{A}) \\frac{\\|\\triangle \\mathbf{A}\\|}{\\|\\mathbf{A}\\|},$$\n",
    "in the limit $\\|\\triangle \\mathbf{A}\\| \\rightarrow 0$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17414a6",
   "metadata": {},
   "source": [
    ". . .\n",
    "\n",
    "::: {.callout-caution icon=false}\n",
    "## Exercise: Lower bound on condition number\n",
    "Show that $\\kappa(\\mathbf{A}) \\ge 1$.\n",
    ":::\n",
    "<details><summary>Answer:</summary> \n",
    "We have $1 = \\|\\mathbf{I}\\| = \\|\\mathbf{A}\\mathbf{A}^{-1}\\| \\le \\|\\mathbf{A}\\|\\|\\mathbf{A}^{-1}\\| = \\kappa(\\mathbf{A}).$\n",
    "</details>\n",
    "\n",
    "[A condition number equal to 1 is the best we can hope for -- this means the relative perturbation in the solution is the same size as that of the data.  If a matrix has condition number $10^t$ indicates that in floating-point arithmetic, roughly $t$ digits are lost in computing the solution $\\mathbf{x}$.  If $\\kappa(\\mathbf{A})> 1/\\epsilon_{\\text{mach}}$, then for numerical purposes, the matrix $\\mathbf{A}$ is effectively singular.  ]{.content-hidden when-format='revealjs' when-format='pptx'} \n",
    "\n",
    "---\n",
    "\n",
    "[Julia has the function `cond` to compute the matrix condition number.  The $\\ell_2$ norm is used by default in this calculation.]{.content-hidden when-format='revealjs' when-format='pptx'} We'll begin with an example of a *Hilbert matrix* which is famously ill-conditioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e8fc3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.109816297946132e7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "A = [ 1/(i+j) for i in 1:6, j in 1:6 ]\n",
    "κ = cond(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996db9f",
   "metadata": {},
   "source": [
    "When solving a linear system with this matrix, we will lose nearly 8 digits of accuracy due to the ill-conditioning of this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8033933",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1:6\n",
    "b = A*x;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8143894b",
   "metadata": {},
   "source": [
    "We perturb the system randomly by $10^{-10}$ in norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "440c4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "◬A = randn(size(A)); ◬A = 1e-10*(◬A/opnorm(◬A));\n",
    "◬b = randn(size(b)); ◬b = 1e-10*normalize(◬b);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45de22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We solve the perturbed problem and see how the solution is changled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe21fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       "  1.1053746015177168e-5\n",
       " -0.00017684631114378568\n",
       "  0.0008826710483242906\n",
       " -0.001887105940777456\n",
       "  0.0018119922449173487\n",
       " -0.0006427654517580095"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = ((A + ◬A) \\ (b+◬b))\n",
    "◬x = new_x - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "976a41af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative_error = norm(◬x) / norm(x) = 0.0002977597146152902\n"
     ]
    }
   ],
   "source": [
    "@show relative_error = norm(◬x) / norm(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "108d1a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper bound due to b: 0.0006723667714371329\n",
      "Upper bound due to A: 0.006609488624373632\n"
     ]
    }
   ],
   "source": [
    "println(\"Upper bound due to b: $(κ*norm(◬b)/norm(b))\")\n",
    "println(\"Upper bound due to A: $(κ*norm(◬A)/norm(A))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e18b84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "These errors are due to our manual perturbations we made to the data.  Even just machine roundoff perturbs this data and affects the solution of this ill-conditioned problem.  This error will scale with $\\epsilon_{\\text{mach}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72639305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative_error = norm(◬x) / norm(x) = 7.822650774976615e-10\n",
      "rounding_bound = κ * eps() = 1.134607141116935e-8\n"
     ]
    }
   ],
   "source": [
    "◬x = A\\b - x\n",
    "@show relative_error = norm(◬x)/norm(x);\n",
    "@show rounding_bound = κ*eps();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f4cc9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Larger Hilbert matrices are even more ill-conditioned and their linear systems suffer from more error during solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46abe297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.802584125151949e17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [ 1/(i+j) for i=1:14, j=1:14 ];\n",
    "κ = cond(A)                          #exceeds 1/eps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97ae80e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.8432499613623"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounding_bound = κ*eps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73fff8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative_error = norm(◬x) / norm(x) = 4.469466154206132\n"
     ]
    }
   ],
   "source": [
    "x = 1:14\n",
    "b = A*x\n",
    "◬x = A\\b - x\n",
    "@show relative_error = norm(◬x)/norm(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d87d31",
   "metadata": {},
   "source": [
    ". . .\n",
    "\n",
    "There are zero accurate digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa762618",
   "metadata": {},
   "source": [
    "## Residual and backward error\n",
    "\n",
    "When we don't know the solution of a linear system, we cannot compare our approximate computed solution to the true solution, so we use the residual error.\n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "## Definition: Residual of a linear system\n",
    "For the problem $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$, the **residual** at a solution estimate $\\hat{\\mathbf{x}}$ is $$\\mathbf{r} = \\mathbf{b} - \\mathbf{A}\\hat{\\mathbf{x}}.$$\n",
    ":::\n",
    "\n",
    ". . . \n",
    "\n",
    "A zero residual means we have an exact solution, and if the matrix is rank $n$, then we have $\\hat{\\mathbf{x}} = \\mathbf{x}$.  \n",
    "\n",
    ". . .\n",
    "\n",
    "More generally, though, we have $$\\mathbf{A}\\hat{\\mathbf{x}} = \\mathbf{b} - \\mathbf{r}.$$  This means that $\\hat{\\mathbf{x}}$ is an exact solution for a linear system with right hand error changed by $-\\mathbf{r}$.  \n",
    "\n",
    ". . .\n",
    "\n",
    "This is what we search for when studying background error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4905ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Hence, residual error of a linear system is the system's backward error.  We can connect this error to the forward error by making the definition $\\mathbf{h} = \\hat{\\mathbf{x}} - \\mathbf{x}$ in the equation $\\mathbf{A}(\\mathbf{x}+\\mathbf{h}) = \\mathbf{b}+\\mathbf{d}$.\n",
    "\n",
    ". . .\n",
    "\n",
    "Then $$\\mathbf{d} = \\mathbf{A}(\\mathbf{x}+\\mathbf{h}) - \\mathbf{b} = \\mathbf{A}\\mathbf{h} = -\\mathbf{r}.$$\n",
    "\n",
    ". . .\n",
    "\n",
    "Thus, our previous theorem yields $$\\frac{\\|\\mathbf{x} - \\hat{\\mathbf{x}}\\|}{\\|\\mathbf{x}\\|} \\le \\kappa(\\mathbf{A}) \\frac{\\|\\mathbf{r}\\|}{\\|\\mathbf{b}\\|}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae4858",
   "metadata": {},
   "source": [
    "[The relationship between relative error and the relative residual is scaling by the matrix condition number.]{.content-hidden when-format='revealjs' when-format='pptx'} \n",
    "\n",
    ". . .\n",
    "\n",
    "::: {.callout-warning icon=false}\n",
    "## Fact: \n",
    "When solving a linear system, we can only expect that the backward (residual) error is small, not the error, since this will suffer from scaling by the matrix condition number.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c4996",
   "metadata": {},
   "source": [
    "# Matrix structure\n",
    "\n",
    "Many matrices typically encountered in scientific computing have special structure.  It can be *very* helpful to understand and exploit these special structures!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfdc7b",
   "metadata": {},
   "source": [
    "## Diagonal dominance\n",
    "\n",
    "An $n \\times n$ matrix $\\mathbf{A}$ is **(row) diagonally dominant** if $$|A_{ii}| > \\sum_{j=1//j\\not=i}^n |A_{ij}| \\text{ for each } i=1, \\cdots, n.$$ [This says that the magnitude of entries on the diagonal are larger than the sum of magnitudes of entries in the same row off-diagonal.]{.content-hidden when-format='revealjs' when-format='pptx'} \n",
    "\n",
    ". . .\n",
    "\n",
    "* Diagonally dominant matrices are guaranteed to be invertible.\n",
    "* Diagonally dominant matrices do not need row-pivoting for elimination/LU stability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b9653",
   "metadata": {},
   "source": [
    "## Banded matrices\n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "## Definition: Bandwidth\n",
    "A matrix $\\mathbf{A}$ has **upper bandwidth** $b_u$ if $j - i > b_u$ implies $A_{ij} = 0$, and **lower bandwidth** $b_l$ if $i-j > b_l$ implies $A_{ij} = 0$.  We say the total **bandwidth** is $b_u + b_l + 1$.  When $b_u = b_l = 1$, we have the important case of a **tridiagonal matrix**.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf7e4826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Matrix{Int64}:\n",
       " 2  -1   0   0   0   0\n",
       " 4   2  -1   0   0   0\n",
       " 0   3   0  -1   0   0\n",
       " 0   0   2   2  -1   0\n",
       " 0   0   0   1   1  -1\n",
       " 0   0   0   0   0   2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = diagm( -1=>[4,3,2,1,0], 0=>[2,2,0,2,1,2], 1=>fill(-1,5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6972ea9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f135ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 LowerTriangular{Float64, Matrix{Float64}}:\n",
       " 1.0   ⋅     ⋅        ⋅         ⋅    ⋅ \n",
       " 2.0  1.0    ⋅        ⋅         ⋅    ⋅ \n",
       " 0.0  0.75  1.0       ⋅         ⋅    ⋅ \n",
       " 0.0  0.0   2.66667  1.0        ⋅    ⋅ \n",
       " 0.0  0.0   0.0      0.214286  1.0   ⋅ \n",
       " 0.0  0.0   0.0      0.0       0.0  1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using FundamentalsNumericalComputation\n",
    "\n",
    "L,U = FNC.lufact(A)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b93e767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 UpperTriangular{Float64, Matrix{Float64}}:\n",
       " 2.0  -1.0   0.0    0.0       0.0       0.0\n",
       "  ⋅    4.0  -1.0    0.0       0.0       0.0\n",
       "  ⋅     ⋅    0.75  -1.0       0.0       0.0\n",
       "  ⋅     ⋅     ⋅     4.66667  -1.0       0.0\n",
       "  ⋅     ⋅     ⋅      ⋅        1.21429  -1.0\n",
       "  ⋅     ⋅     ⋅      ⋅         ⋅        2.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b3906",
   "metadata": {},
   "source": [
    "The LU factors are also banded!\n",
    "\n",
    "::: {.callout-tip icon=false}\n",
    "## Note: \n",
    "The number of flops needed by LU factorization without pivoting is $\\mathcal{O}(b_u b_t n)$ when the upper and lower bandwidths are $b_u$ and $b_l$.\n",
    ":::\n",
    "\n",
    "---\n",
    "\n",
    "In order for Julia to take advantage of banded matrix advantages if we use an ordinary (dense) matrix representation (since it doesn't know in advance where the zeros are)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c80f9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.737181 seconds (7 allocations: 763.016 MiB, 0.76% gc time)\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "A = diagm(0=>1:n, 1=>n-1:-1:1, -1=>ones(n-1))\n",
    "lu(rand(3,3)) #throwaway to force compilation\n",
    "@time lu(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b760e5",
   "metadata": {},
   "source": [
    ". . .\n",
    "\n",
    "If we use a sparse matrix representation, the speedup is dramatic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73fe4188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.002840 seconds (86 allocations: 9.920 MiB)\n"
     ]
    }
   ],
   "source": [
    "A = spdiagm(0=>1:n, 1=>n-1:-1:1, -1=>ones(n-1))\n",
    "lu(A); #throwaway for sparse compile\n",
    "@time lu(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebfb62",
   "metadata": {},
   "source": [
    "## Sparse matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c12669-a869-46d9-aa62-bbb2a02b1783",
   "metadata": {},
   "source": [
    "<!--\n",
    "[verbose test]{.content-hidden when-format=\"revealjs\" when-format=\"pptx\"}\n",
    "\n",
    "::: {.callout-caution icon=false}\n",
    "## Exercise: \n",
    "\n",
    ":::\n",
    "\n",
    "<details><summary>Answer:</summary> </details>\n",
    "\n",
    "\n",
    "::: {.callout-note icon=false}\n",
    "## Definition: \n",
    " \n",
    ":::\n",
    "\n",
    "\n",
    "::: {.callout-tip icon=false}\n",
    "## Note: \n",
    " \n",
    ":::\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
